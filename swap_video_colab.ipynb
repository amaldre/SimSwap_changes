{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6YqwUkU7d2V"
      },
      "source": [
        "# **FIXES APPLIED**\n",
        "\n",
        "Antelope onnx downloaded (see this issue : https://github.com/neuralchen/SimSwap/issues/477#issuecomment-2547691671).\n",
        "\n",
        "Multiple np.float, not valid since numpy 1.24.0, removed with find and replace in all files.\n",
        "\n",
        "All checkpoints downloaded automatically\n",
        "\n",
        "# **HOW TO SWAP**\n",
        "\n",
        "Use this code :\n",
        "\n",
        "!python test_video_swapsingle.py \\\n",
        "  --isTrain false \\\n",
        "  --name people \\\n",
        "  --Arc_path arcface_model/arcface_checkpoint.tar \\\n",
        "  --pic_a_path image.jpg \\\n",
        "  --video_path video.mp4 \\\n",
        "  --output_path output.mp4 \\\n",
        "  --temp_path ./temp_results \\\n",
        "  --no_simswaplogo \\\n",
        "  --use_mask \\\n",
        "  --crop_size 512\n",
        "\n",
        "Change pic_a_path to change the face to apply, and video_path to change the video to swap.\n",
        "Use 512 to have better results, and 224 if the results with 512 are not natural.\n",
        "\n",
        "# **PROBLEM**\n",
        "\n",
        "Impossible to run the notebook without GPU on colab\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_gtFoV8BuRx"
      },
      "source": [
        "This is an example of SimSwap on processing video with multiple faces with designated sources.\n",
        "\n",
        "Code path: https://github.com/neuralchen/SimSwap\n",
        "Paper path: https://arxiv.org/pdf/2106.06340v1.pdf."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y1RfpzsCAl9",
        "outputId": "5c13c0ea-7d92-459d-99d1-7ab59697cf1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Jul  7 07:12:35 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "## make sure you are using a runtime with GPU\n",
        "## you can check at Runtime/ChaAnge runtime type in the top bar.\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Qzzx2UpDkqw"
      },
      "source": [
        "All file changes make by this notebook are temporary.\n",
        "You can try to mount your own google drive to store files if you wang.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA_4CeWZCHLP",
        "outputId": "361eca6d-afb8-4a92-f304-ab31c4527362"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'SimSwap'...\n",
            "remote: Enumerating objects: 1141, done.\u001b[K\n",
            "remote: Counting objects: 100% (501/501), done.\u001b[K\n",
            "remote: Compressing objects: 100% (117/117), done.\u001b[K\n",
            "remote: Total 1141 (delta 415), reused 384 (delta 384), pack-reused 640 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1141/1141), 211.47 MiB | 15.39 MiB/s, done.\n",
            "Resolving deltas: 100% (601/601), done.\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/neuralchen/SimSwap\n",
        "!cd SimSwap && git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TitoVESuCR4",
        "outputId": "7840ee1b-534a-407e-9487-4b4f3691b5e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.5.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (780.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.5/780.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.1.6\n",
            "  Downloading https://download.pytorch.org/whl/torchvision-0.1.6-py3-none-any.whl (16 kB)\n",
            "Collecting torchaudio==2.5.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m121.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (2.21.5)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.5.1) (12.5.82)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.1) (3.0.2)\n",
            "Installing collected packages: torchvision, triton, nvidia-nvtx-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchaudio\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torchvision>=0.11, but you have torchvision 0.1.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nvtx-cu12-12.1.105 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.1.6 triton-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.5.1 torchvision==0.1.6 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5K4au_UCkKn",
        "outputId": "90cef14d-9c52-490d-ce4d-21a6aabbfc3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting insightface==0.2.1\n",
            "  Downloading insightface-0.2.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from insightface==0.2.1) (2.0.2)\n",
            "Collecting onnx (from insightface==0.2.1)\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from insightface==0.2.1) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from insightface==0.2.1) (2.32.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from insightface==0.2.1) (3.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from insightface==0.2.1) (11.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from insightface==0.2.1) (1.15.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from insightface==0.2.1) (4.11.0.86)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from insightface==0.2.1) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from insightface==0.2.1) (0.25.2)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.11/dist-packages (from insightface==0.2.1) (1.13)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.12)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->insightface==0.2.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->insightface==0.2.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->insightface==0.2.1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->insightface==0.2.1) (2025.6.15)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface==0.2.1) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface==0.2.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface==0.2.1) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface==0.2.1) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface==0.2.1) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface==0.2.1) (2.9.0.post0)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx->insightface==0.2.1) (4.14.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface==0.2.1) (3.5)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface==0.2.1) (2025.6.11)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface==0.2.1) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->insightface==0.2.1) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->insightface==0.2.1) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->insightface==0.2.1) (1.17.0)\n",
            "Downloading insightface-0.2.1-py2.py3-none-any.whl (24 kB)\n",
            "Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx, humanfriendly, coloredlogs, onnxruntime, insightface\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 insightface-0.2.1 onnx-1.18.0 onnxruntime-1.22.0\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from googledrivedownloader) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->googledrivedownloader) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->googledrivedownloader) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->googledrivedownloader) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->googledrivedownloader) (2025.6.15)\n",
            "Collecting imageio==2.4.1\n",
            "  Downloading imageio-2.4.1.tar.gz (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imageio==2.4.1) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from imageio==2.4.1) (11.2.1)\n",
            "Building wheels for collected packages: imageio\n",
            "  Building wheel for imageio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imageio: filename=imageio-2.4.1-py3-none-any.whl size=3303884 sha256=457d25ada5ab75b137224773a9899c8578592d63d0aa7ed7537e5105c482d41d\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/28/50/248b15750b57c6b163d89d265f242e9cf6bce0bedfea3120aa\n",
            "Successfully built imageio\n",
            "Installing collected packages: imageio\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.37.0\n",
            "    Uninstalling imageio-2.37.0:\n",
            "      Successfully uninstalled imageio-2.37.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scikit-image 0.25.2 requires imageio!=2.35.0,>=2.33, but you have imageio 2.4.1 which is incompatible.\n",
            "moviepy 1.0.3 requires imageio<3.0,>=2.5; python_version >= \"3.4\", but you have imageio 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed imageio-2.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install insightface==0.2.1 onnxruntime moviepy\n",
        "!pip install googledrivedownloader\n",
        "!pip install imageio==2.4.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQ7ZoIbLFCye",
        "outputId": "93825473-4fa0-4ceb-e42f-495a975ad3bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " cog.yaml\t       README.md\n",
            " crop_224\t      'SimSwap colab.ipynb'\n",
            " data\t\t       simswaplogo\n",
            " demo_file\t       test_one_image.py\n",
            " docs\t\t       test_video_swapmulti.py\n",
            " download-weights.sh   test_video_swap_multispecific.py\n",
            " insightface_func      test_video_swapsingle.py\n",
            " LICENSE\t       test_video_swapspecific.py\n",
            " models\t\t       test_wholeimage_swapmulti.py\n",
            " MultiSpecific.ipynb   test_wholeimage_swap_multispecific.py\n",
            " options\t       test_wholeimage_swapsingle.py\n",
            " output\t\t       test_wholeimage_swapspecific.py\n",
            " parsing_model\t       train.ipynb\n",
            " pg_modules\t       train.py\n",
            " predict.py\t       util\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(\"SimSwap\")\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZvGp-p0nOmKE"
      },
      "outputs": [],
      "source": [
        "## You can upload filed manually\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLti1J0pEFjJ",
        "outputId": "35a5f068-eb93-4720-c401-6da54ca8a717"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-07-07 07:16:02--  https://github.com/neuralchen/SimSwap/releases/download/1.0/arcface_checkpoint.tar\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/374891081/f01468b3-446b-4867-8c78-6d496183f9e6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250707%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250707T071602Z&X-Amz-Expires=1800&X-Amz-Signature=8b269c920612b1e2d6de1902aee054d6aadde0d93c15c2bac83da0eccc76cb35&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Darcface_checkpoint.tar&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-07-07 07:16:02--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/374891081/f01468b3-446b-4867-8c78-6d496183f9e6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250707%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250707T071602Z&X-Amz-Expires=1800&X-Amz-Signature=8b269c920612b1e2d6de1902aee054d6aadde0d93c15c2bac83da0eccc76cb35&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Darcface_checkpoint.tar&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 209280521 (200M) [application/octet-stream]\n",
            "Saving to: ‘./arcface_model/arcface_checkpoint.tar’\n",
            "\n",
            "arcface_checkpoint. 100%[===================>] 199.58M  37.7MB/s    in 5.3s    \n",
            "\n",
            "2025-07-07 07:16:09 (37.7 MB/s) - ‘./arcface_model/arcface_checkpoint.tar’ saved [209280521/209280521]\n",
            "\n",
            "--2025-07-07 07:16:09--  https://github.com/neuralchen/SimSwap/releases/download/1.0/checkpoints.zip\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/374891081/a8dac400-dcb6-11eb-933f-977cd7f5f554?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250707%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250707T071609Z&X-Amz-Expires=1800&X-Amz-Signature=d02a1a0dfc68eab44fe3f377cf006cc3c0a1024759d75e8a27ed0ce65eaea096&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcheckpoints.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-07-07 07:16:09--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/374891081/a8dac400-dcb6-11eb-933f-977cd7f5f554?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250707%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250707T071609Z&X-Amz-Expires=1800&X-Amz-Signature=d02a1a0dfc68eab44fe3f377cf006cc3c0a1024759d75e8a27ed0ce65eaea096&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcheckpoints.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 256461775 (245M) [application/octet-stream]\n",
            "Saving to: ‘checkpoints.zip’\n",
            "\n",
            "checkpoints.zip     100%[===================>] 244.58M  36.6MB/s    in 6.7s    \n",
            "\n",
            "2025-07-07 07:16:17 (36.8 MB/s) - ‘checkpoints.zip’ saved [256461775/256461775]\n",
            "\n",
            "Archive:  ./checkpoints.zip\n",
            "   creating: ./checkpoints/people/\n",
            "  inflating: ./checkpoints/people/iter.txt  \n",
            "  inflating: ./checkpoints/people/latest_net_D1.pth  \n",
            "  inflating: ./checkpoints/people/latest_net_D2.pth  \n",
            "  inflating: ./checkpoints/people/latest_net_G.pth  \n",
            "  inflating: ./checkpoints/people/loss_log.txt  \n",
            "  inflating: ./checkpoints/people/opt.txt  \n",
            "   creating: ./checkpoints/people/web/\n",
            "   creating: ./checkpoints/people/web/images/\n",
            "--2025-07-07 07:16:20--  https://github.com/neuralchen/SimSwap/releases/download/1.0/79999_iter.pth\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/374891081/6f43c2ff-c59c-48ad-9854-392249307d00?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250707%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250707T071620Z&X-Amz-Expires=1800&X-Amz-Signature=59220783c4ea2e431ef8fb6fa700741d42ecce3f5b4f86c017aca6b8699fae4a&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D79999_iter.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-07-07 07:16:20--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/374891081/6f43c2ff-c59c-48ad-9854-392249307d00?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250707%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250707T071620Z&X-Amz-Expires=1800&X-Amz-Signature=59220783c4ea2e431ef8fb6fa700741d42ecce3f5b4f86c017aca6b8699fae4a&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D79999_iter.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53289463 (51M) [application/octet-stream]\n",
            "Saving to: ‘./parsing_model/checkpoint/79999_iter.pth’\n",
            "\n",
            "79999_iter.pth      100%[===================>]  50.82M  23.6MB/s    in 2.2s    \n",
            "\n",
            "2025-07-07 07:16:23 (23.6 MB/s) - ‘./parsing_model/checkpoint/79999_iter.pth’ saved [53289463/53289463]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#from google_drive_downloader import GoogleDriveDownloader\n",
        "\n",
        "### it seems that google drive link may not be permenant, you can find this ID from our open url.\n",
        "# GoogleDriveDownloader.download_file_from_google_drive(file_id='1TLNdIufzwesDbyr_nVTR7Zrx9oRHLM_N',\n",
        "#                                     dest_path='./arcface_model/arcface_checkpoint.tar')\n",
        "# GoogleDriveDownloader.download_file_from_google_drive(file_id='1PXkRiBUYbu1xWpQyDEJvGKeqqUFthJcI',\n",
        "#                                     dest_path='./checkpoints.zip')\n",
        "\n",
        "# ARCFACE\n",
        "\n",
        "!wget -P ./arcface_model https://github.com/neuralchen/SimSwap/releases/download/1.0/arcface_checkpoint.tar\n",
        "\n",
        "# CHECKPOINTS.ZIP\n",
        "\n",
        "!wget https://github.com/neuralchen/SimSwap/releases/download/1.0/checkpoints.zip\n",
        "!unzip ./checkpoints.zip  -d ./checkpoints\n",
        "\n",
        "# 512.zip\n",
        "\n",
        "!wget https://github.com/neuralchen/SimSwap/releases/download/512_beta/512.zip\n",
        "!unzip ./512.zip  -d ./checkpoints\n",
        "\n",
        "!wget -P ./parsing_model/checkpoint https://github.com/neuralchen/SimSwap/releases/download/1.0/79999_iter.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NZMS4Jqi-Q7y"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXxxAsdL87I-",
        "outputId": "ff83d326-6589-404c-adf5-227ab1bb5c54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1goH5lO8BAhTpRhpBeXqWEcGkxiiLlgx9\n",
            "From (redirected): https://drive.google.com/uc?id=1goH5lO8BAhTpRhpBeXqWEcGkxiiLlgx9&confirm=t&uuid=e4ed1870-48d4-48ca-a820-634e51b49a44\n",
            "To: /content/SimSwap/insightface_func/models/antelope/antelope.zip\n",
            "100% 248M/248M [00:05<00:00, 42.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "# ANTELOPE\n",
        "\n",
        "!mkdir -p insightface_func/models/antelope\n",
        "!gdown --id 1goH5lO8BAhTpRhpBeXqWEcGkxiiLlgx9 -O insightface_func/models/antelope/antelope.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikd2kvdy-PWq",
        "outputId": "3fedfc4e-99f9-475f-ff1d-a38ac1392a8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  insightface_func/models/antelope/antelope.zip\n",
            "   creating: insightface_func/models/antelope/antelope/\n",
            "  inflating: insightface_func/models/antelope/antelope/glintr100.onnx  \n",
            "  inflating: insightface_func/models/antelope/antelope/scrfd_10g_bnkps.onnx  \n"
          ]
        }
      ],
      "source": [
        "!unzip -o insightface_func/models/antelope/antelope.zip -d insightface_func/models/antelope/\n",
        "!rm insightface_func/models/antelope/antelope.zip\n",
        "!mv ./insightface_func/models/antelope/antelope/* ./insightface_func/models/antelope/\n",
        "!rm -rf ./insightface_func/models/antelope/antelope"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuasEfW--iRd",
        "outputId": "4218fbc0-b3ca-4254-f538-cf3636f1f45e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 265M\n",
            "-rw-r--r-- 1 root root 249M May  4  2021 glintr100.onnx\n",
            "-rw-r--r-- 1 root root  17M May  4  2021 scrfd_10g_bnkps.onnx\n"
          ]
        }
      ],
      "source": [
        "!ls -lh ./insightface_func/models/antelope/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfSsND36EMvn",
        "outputId": "18a220f8-19b3-4d18-a54c-9246c86a35e0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import fractions\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from models.models import create_model\n",
        "from options.test_options import TestOptions\n",
        "from insightface_func.face_detect_crop_multi import Face_detect_crop\n",
        "from util.videoswap_multispecific import video_swap\n",
        "import os\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rxSbZ2EDNDlf"
      },
      "outputs": [],
      "source": [
        "def lcm(a, b): return abs(a * b) / fractions.gcd(a, b) if a and b else 0\n",
        "\n",
        "transformer = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "transformer_Arcface = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ye8iS0UVPMRg",
        "outputId": "268eaf65-a33d-4653-c713-5daf5121497d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "people\n"
          ]
        }
      ],
      "source": [
        "!ls ./checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwJOwR9LNKRz",
        "outputId": "9cbc251f-e213-45bf-a6ac-2f1f42b0a331"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 512\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "f: /root/.local/share/jupyter/runtime/kernel-2cd0b61e-a4e0-449d-979b-2e9bf6836500.json\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: people\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./output/\n",
            "phase: test\n",
            "pic_a_path: G:/swap_data/ID/elon-musk-hero-image.jpeg\n",
            "pic_b_path: ./demo_file/multi_people.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: False\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: latest\n",
            "-------------- End ----------------\n"
          ]
        }
      ],
      "source": [
        "opt = TestOptions()\n",
        "opt.initialize()\n",
        "opt.parser.add_argument('-f') ## dummy arg to avoid bug\n",
        "opt = opt.parse()\n",
        "opt.multisepcific_dir = './demo_file/multispecific' ## or replace it with folder from your own google drive\n",
        "                           ## and remember to follow the dir structure in usage.md\n",
        "opt.video_path = './demo_file/multi_people_1080p.mp4' ## or replace it with video from your own google drive\n",
        "opt.output_path = './output/multi_test_multispecific.mp4'\n",
        "opt.temp_path = './tmp'\n",
        "opt.Arc_path = './arcface_model/arcface_checkpoint.tar'\n",
        "opt.name = 'people'\n",
        "opt.isTrain = False\n",
        "opt.use_mask = True  ## new feature up-to-date\n",
        "\n",
        "crop_size = opt.crop_size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOO3xg2I7A4l",
        "outputId": "a60c6abb-3747-4da9-c23c-7187f1e98722"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before find and replace np.float :\n",
            "\n",
            "\n",
            "After find and replance np.float :\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Before find and replace np.float :\\n\")\n",
        "!find . -name \"*.py\" -exec sed -i 's/np\\.float/float/g' {} +\n",
        "print(\"\\nAfter find and replance np.float :\\n\")\n",
        "!grep -r \"np.float\" /content/SimSwap/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFt8zQrAMq9F",
        "outputId": "daae91c0-c399-4e15-ef59-1fcc6f31397f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pretrained network G has fewer layers; The following are not initialized:\n",
            "['down0', 'first_layer', 'last_layer', 'up0']\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "(142, 366, 4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 594/594 [12:24<00:00,  1.25s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Building video ./output/multi_test_multispecific.mp4.\n",
            "MoviePy - Writing audio in multi_test_multispecificTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video ./output/multi_test_multispecific.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready ./output/multi_test_multispecific.mp4\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.float = float\n",
        "\n",
        "pic_specific = opt.pic_specific_path\n",
        "crop_size = 224\n",
        "multisepcific_dir = opt.multisepcific_dir\n",
        "\n",
        "torch.nn.Module.dump_patches = False\n",
        "model = create_model(opt)\n",
        "model.eval()\n",
        "\n",
        "app = Face_detect_crop(name='antelope', root='./insightface_func/models')\n",
        "app.prepare(ctx_id= 0, det_thresh=0.6, det_size=(640,640))\n",
        "# The specific person to be swapped(source)\n",
        "source_specific_id_nonorm_list = []\n",
        "source_path = os.path.join(multisepcific_dir,'SRC_*')\n",
        "source_specific_images_path = sorted(glob.glob(source_path))\n",
        "\n",
        "with torch.no_grad():\n",
        "    for source_specific_image_path in source_specific_images_path:\n",
        "        specific_person_whole = cv2.imread(source_specific_image_path)\n",
        "        specific_person_align_crop, _ = app.get(specific_person_whole,crop_size)\n",
        "        specific_person_align_crop_pil = Image.fromarray(cv2.cvtColor(specific_person_align_crop[0],cv2.COLOR_BGR2RGB))\n",
        "        specific_person = transformer_Arcface(specific_person_align_crop_pil)\n",
        "        specific_person = specific_person.view(-1, specific_person.shape[0], specific_person.shape[1], specific_person.shape    [2])\n",
        "        # convert numpy to tensor\n",
        "        specific_person = specific_person.cuda()\n",
        "        #create latent id\n",
        "        specific_person_downsample = F.interpolate(specific_person, size=(112,112))\n",
        "        specific_person_id_nonorm = model.netArc(specific_person_downsample)\n",
        "        source_specific_id_nonorm_list.append(specific_person_id_nonorm.clone())\n",
        "\n",
        "    # The person who provides id information (list)\n",
        "    target_id_norm_list = []\n",
        "    target_path = os.path.join(multisepcific_dir,'DST_*')\n",
        "    target_images_path = sorted(glob.glob(target_path))\n",
        "\n",
        "    for target_image_path in target_images_path:\n",
        "        img_a_whole = cv2.imread(target_image_path)\n",
        "        img_a_align_crop, _ = app.get(img_a_whole,crop_size)\n",
        "        img_a_align_crop_pil = Image.fromarray(cv2.cvtColor(img_a_align_crop[0],cv2.COLOR_BGR2RGB))\n",
        "        img_a = transformer_Arcface(img_a_align_crop_pil)\n",
        "        img_id = img_a.view(-1, img_a.shape[0], img_a.shape[1], img_a.shape[2])\n",
        "        # convert numpy to tensor\n",
        "        img_id = img_id.cuda()\n",
        "        #create latent id\n",
        "        img_id_downsample = F.interpolate(img_id, size=(112,112))\n",
        "        latend_id = model.netArc(img_id_downsample)\n",
        "        latend_id = F.normalize(latend_id, p=2, dim=1)\n",
        "        target_id_norm_list.append(latend_id.clone())\n",
        "\n",
        "    assert len(target_id_norm_list) == len(source_specific_id_nonorm_list), \"The number of images in source and target  directory must be same !!!\"\n",
        "    video_swap(opt.video_path, target_id_norm_list,source_specific_id_nonorm_list, opt.id_thres, \\\n",
        "        model, app, opt.output_path,temp_results_dir=opt.temp_path,no_simswaplogo=opt.no_simswaplogo,use_mask=opt.use_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rty2GsyZZrI6",
        "outputId": "0902ab24-bb9d-4868-98cf-d76b90fd1ff6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: people\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: False\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: output/\n",
            "phase: test\n",
            "pic_a_path: demo_file/Iron_man.jpg\n",
            "pic_b_path: demo_file/specific3.png\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: False\n",
            "verbose: False\n",
            "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
            "which_epoch: latest\n",
            "-------------- End ----------------\n",
            "/content/SimSwap/models/fs_model.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  netArc_checkpoint = torch.load(netArc_checkpoint, map_location=torch.device(\"cpu\"))\n",
            "/content/SimSwap/models/base_model.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  network.load_state_dict(torch.load(save_path))\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
            "/content/SimSwap/test_one_image.py:59: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  latend_id = latend_id/np.linalg.norm(latend_id,axis=1,keepdims=True)\n",
            "[ WARN:0@4.095] global loadsave.cpp:848 imwrite_ Unsupported depth image for selected encoder is fallbacked to CV_8U.\n"
          ]
        }
      ],
      "source": [
        "!python test_one_image.py --name people --Arc_path arcface_model/arcface_checkpoint.tar --pic_a_path demo_file/Iron_man.jpg --pic_b_path demo_file/specific3.png --output_path output/ --crop_size 224\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W36MAFN04ob5",
        "outputId": "4ae06f96-6f0c-4d6a-e34d-d05adebd8d68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "error: XDG_RUNTIME_DIR not set in the environment.\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 224\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: people\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: True\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./output/result.mp4\n",
            "phase: test\n",
            "pic_a_path: ./source_image_video/image2.jpeg\n",
            "pic_b_path: ./demo_file/multi_people.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: ./source_image_video/video2.mp4\n",
            "which_epoch: latest\n",
            "-------------- End ----------------\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "(142, 366, 4)\n",
            "100% 267/267 [02:54<00:00,  1.53it/s]\n",
            "Moviepy - Building video ./output/result.mp4.\n",
            "MoviePy - Writing audio in resultTEMP_MPY_wvf_snd.mp4\n",
            "MoviePy - Done.\n",
            "Moviepy - Writing video ./output/result.mp4\n",
            "\n",
            "Moviepy - Done !\n",
            "Moviepy - video ready ./output/result.mp4\n"
          ]
        }
      ],
      "source": [
        "!python test_video_swapsingle.py \\\n",
        "  --isTrain false \\\n",
        "  --name people \\\n",
        "  --Arc_path arcface_model/arcface_checkpoint.tar \\\n",
        "  --pic_a_path ./source_image_video/image2.jpeg \\\n",
        "  --video_path ./source_image_video/video2.mp4 \\\n",
        "  --output_path ./output/result.mp4 \\\n",
        "  --temp_path ./temp_results \\\n",
        "  --no_simswaplogo \\\n",
        "  --use_mask \\\n",
        "  --crop_size 224\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb7owh9R99cc",
        "outputId": "c8876605-4e16-481e-dc78-d3aed11517da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "error: XDG_RUNTIME_DIR not set in the environment.\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 512\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: people\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: True\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./output/result_512.mp4\n",
            "phase: test\n",
            "pic_a_path: ./source_image_video/image2.jpeg\n",
            "pic_b_path: ./demo_file/multi_people.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results_512\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: ./source_image_video/video2.mp4\n",
            "which_epoch: latest\n",
            "-------------- End ----------------\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "(142, 366, 4)\n",
            "100% 267/267 [02:53<00:00,  1.54it/s]\n",
            "Moviepy - Building video ./output/result_512.mp4.\n",
            "MoviePy - Writing audio in result_512TEMP_MPY_wvf_snd.mp4\n",
            "MoviePy - Done.\n",
            "Moviepy - Writing video ./output/result_512.mp4\n",
            "\n",
            "Moviepy - Done !\n",
            "Moviepy - video ready ./output/result_512.mp4\n"
          ]
        }
      ],
      "source": [
        "!python test_video_swapsingle.py \\\n",
        "  --isTrain false \\\n",
        "  --name people \\\n",
        "  --Arc_path arcface_model/arcface_checkpoint.tar \\\n",
        "  --pic_a_path ./source_image_video/image2.jpeg \\\n",
        "  --video_path ./source_image_video/video2.mp4 \\\n",
        "  --output_path ./output/result_512.mp4 \\\n",
        "  --temp_path ./temp_results_512 \\\n",
        "  --no_simswaplogo \\\n",
        "  --use_mask \\\n",
        "  --crop_size 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FH3zgX_8_AU",
        "outputId": "f4109af7-b75a-4dab-d4b0-af7bd8dd9801"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "error: XDG_RUNTIME_DIR not set in the environment.\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 512\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: people\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: True\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./output/swap_alex.mp4\n",
            "phase: test\n",
            "pic_a_path: ./source_image_video/face_ryan.jpg\n",
            "pic_b_path: ./demo_file/multi_people.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results_swap_alex\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: ./source_image_video/face_alex.mp4\n",
            "which_epoch: latest\n",
            "-------------- End ----------------\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "(142, 366, 4)\n",
            " 77% 275/355 [03:03<00:53,  1.50it/s]\n",
            "Moviepy - Building video ./output/swap_alex.mp4.\n",
            "Moviepy - Writing video ./output/swap_alex.mp4\n",
            "\n",
            "Moviepy - Done !\n",
            "Moviepy - video ready ./output/swap_alex.mp4\n",
            "error: XDG_RUNTIME_DIR not set in the environment.\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 512\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: people\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: True\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./output/swap_guy_no_glass.mp4\n",
            "phase: test\n",
            "pic_a_path: ./source_image_video/face_will.jpg\n",
            "pic_b_path: ./demo_file/multi_people.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results_swap_guy_no_glass\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: ./source_image_video/face_guy_no_glass.mp4\n",
            "which_epoch: latest\n",
            "-------------- End ----------------\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "(142, 366, 4)\n",
            "100% 296/296 [03:19<00:00,  1.48it/s]\n",
            "Moviepy - Building video ./output/swap_guy_no_glass.mp4.\n",
            "Moviepy - Writing video ./output/swap_guy_no_glass.mp4\n",
            "\n",
            "Moviepy - Done !\n",
            "Moviepy - video ready ./output/swap_guy_no_glass.mp4\n",
            "error: XDG_RUNTIME_DIR not set in the environment.\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "------------ Options -------------\n",
            "Arc_path: arcface_model/arcface_checkpoint.tar\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 8\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "crop_size: 512\n",
            "data_type: 32\n",
            "dataroot: ./datasets/cityscapes/\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_thres: 0.03\n",
            "image_size: 224\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "latent_size: 512\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "multisepcific_dir: ./demo_file/multispecific\n",
            "nThreads: 2\n",
            "n_blocks_global: 6\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 3\n",
            "n_local_enhancers: 1\n",
            "name: people\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "no_simswaplogo: True\n",
            "norm: batch\n",
            "norm_G: spectralspadesyncbatch3x3\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "output_path: ./output/swap_guy_glass.mp4\n",
            "phase: test\n",
            "pic_a_path: ./source_image_video/face_will.jpg\n",
            "pic_b_path: ./demo_file/multi_people.jpg\n",
            "pic_specific_path: ./crop_224/zrf.jpg\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "semantic_nc: 3\n",
            "serial_batches: False\n",
            "temp_path: ./temp_results_guy_glass\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "use_mask: True\n",
            "verbose: False\n",
            "video_path: ./source_image_video/face_guy_glass.mp4\n",
            "which_epoch: latest\n",
            "-------------- End ----------------\n",
            "input mean and std: 127.5 127.5\n",
            "find model: ./insightface_func/models/antelope/glintr100.onnx recognition\n",
            "find model: ./insightface_func/models/antelope/scrfd_10g_bnkps.onnx detection\n",
            "set det-size: (640, 640)\n",
            "(142, 366, 4)\n",
            " 64% 275/432 [03:00<01:42,  1.53it/s]\n",
            "Moviepy - Building video ./output/swap_guy_glass.mp4.\n",
            "Moviepy - Writing video ./output/swap_guy_glass.mp4\n",
            "\n",
            "Moviepy - Done !\n",
            "Moviepy - video ready ./output/swap_guy_glass.mp4\n"
          ]
        }
      ],
      "source": [
        "!python test_video_swapsingle.py \\\n",
        "  --isTrain false \\\n",
        "  --name people \\\n",
        "  --Arc_path arcface_model/arcface_checkpoint.tar \\\n",
        "  --pic_a_path ./source_image_video/face_ryan.jpg \\\n",
        "  --video_path ./source_image_video/face_alex.mp4 \\\n",
        "  --output_path ./output/swap_alex.mp4 \\\n",
        "  --temp_path ./temp_results_swap_alex \\\n",
        "  --no_simswaplogo \\\n",
        "  --use_mask \\\n",
        "  --crop_size 512\n",
        "\n",
        "!python test_video_swapsingle.py \\\n",
        "  --isTrain false \\\n",
        "  --name people \\\n",
        "  --Arc_path arcface_model/arcface_checkpoint.tar \\\n",
        "  --pic_a_path ./source_image_video/face_will.jpg \\\n",
        "  --video_path ./source_image_video/face_guy_no_glass.mp4 \\\n",
        "  --output_path ./output/swap_guy_no_glass.mp4 \\\n",
        "  --temp_path ./temp_results_swap_guy_no_glass \\\n",
        "  --no_simswaplogo \\\n",
        "  --use_mask \\\n",
        "  --crop_size 512\n",
        "\n",
        "!python test_video_swapsingle.py \\\n",
        "  --isTrain false \\\n",
        "  --name people \\\n",
        "  --Arc_path arcface_model/arcface_checkpoint.tar \\\n",
        "  --pic_a_path ./source_image_video/face_will.jpg \\\n",
        "  --video_path ./source_image_video/face_guy_glass.mp4 \\\n",
        "  --output_path ./output/swap_guy_glass.mp4 \\\n",
        "  --temp_path ./temp_results_guy_glass \\\n",
        "  --no_simswaplogo \\\n",
        "  --use_mask \\\n",
        "  --crop_size 512"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
